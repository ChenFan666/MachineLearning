# 线性回归之Logistic回归
- 回归
	- 在介绍Logistic回归之前，先容我介绍一下什么是回归
	- 回归，指研究一组随机变量(Y1 ，Y2 ，…，Yi)和另一组(X1，X2，…，Xk)变量之间关系的统计分析方法，又称多重回归分析。通常Y1，Y2，…，Yi是因变量，X1、X2，…，Xk是自变量。
	- 若自变量和因变量之间保持一种最基本的线性关系，我们称之为线性回归，最简单的线性回归是指一元线性回归，关系为Y=a+bX+c。
	- 回归研究的过程一般是一个拟合的过程（找寻最佳拟合）。
- Logistic回归
    - 是一种二分类算法（标签只有“是”或者“否”两个选项）
    - 利用Sigmoid函数阈值在[0,1]区间上的特性
    - 主要思想为：根据现有数据对分类边界线建立回归公式
    - 本质上就是一个基于条件概率的判别模型
    - 公式是这样的
    - ![Sigmoid](http://g.recordit.co/VNczQ7JCda.gif)
    - 其中θ是参数列向量(也就是我们要求解的)，x是样本列向量(也就是给定的数据集)，θ的转置和x相乘得到矩阵z，g函数实现了任意实数到[0,1]的映射，这样样本数据集x都可以映射到[0,1]之间进行分类，h函数则给出了输出为1的概率。
    - 这就是说，如果有合适的θ，配合上x，我们通过上述公式可以计算出一个概率来对样本x分类，如果这个概率大于0.5，就说这是一个正样本，否则，这是一个负样本。
	- 问题变为了如何求这个θ了，我们可以通过定义代价函数，配合最大似然估计法，再将公式对数化，得到一个公式，求使公式值最大的θ就可以了，使用梯度上升算法可求。
	- 求出θ，也就得到了分类模型了。
	- 由于主要介绍库内使用，具体数学推导就不多赘述了。
- 算法优点
    - Logistic回归的目的是寻找一个非线性函数Sigmoid的最佳拟合参数，只要找到，对于二分类问题，分类较快。
- 算法缺点
    - 对于多分类问题，存在分类的难度。
- 代码主要演示sklearn中Logistic回归使用，具体实现可以斟酌自行完成。